{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMplX2dnNC4xnCnlfB04XHm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"error","timestamp":1711944588102,"user_tz":-330,"elapsed":7469,"user":{"displayName":"Shivam Singh Barman","userId":"14575192322519287197"}},"outputId":"54b1ee27-a519-4014-e200-f264be2426fd","id":"f6nn5YqU18RD"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at ./segnet_model.h5","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b83ca0644768>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Load SegNet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0msegnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./segnet_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define image path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    231\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./segnet_model.h5"]}],"source":["import numpy as np\n","import cv2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import imagenet_utils\n","from tensorflow.keras.preprocessing import image\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","# Define a function to perform Grad-CAM++\n","def grad_cam_plus_plus(input_model, image, layer_name, class_index, colormap=cv2.COLORMAP_JET):\n","    # Define the loss\n","    loss = input_model.output[:, class_index]\n","\n","    # Get the convolutional layer\n","    conv_layer = input_model.get_layer(layer_name)\n","\n","    # Compute the gradients of the output with respect to the conv layer\n","    grads = K.gradients(loss, conv_layer.output)[0]\n","    # Compute the second-order gradients\n","    grads_sqr = K.gradients(K.sum(grads), conv_layer.output)[0]\n","    # Compute the alpha weights\n","    alpha_num = grads_sqr\n","    alpha_denom = grads_sqr * 2.0 + K.epsilon()\n","    alpha_denom = K.mean(alpha_denom, axis=(1, 2), keepdims=True)\n","    alpha_denom = K.sqrt(alpha_denom)\n","    alphas = alpha_num / alpha_denom\n","\n","    # Compute the weights\n","    weights = K.maximum(grads, 0.0)\n","    # Compute the Grad-CAM++ heatmap\n","    grad_cam_plus_plus = K.sum(weights * alphas, axis=3)\n","\n","    # Define function to get output and gradients\n","    iterate = K.function([input_model.input], [conv_layer.output, grads, grads_sqr])\n","\n","    # Compute convolutional layer output and gradients\n","    conv_output, conv_grads, conv_grads_sqr = iterate([image])\n","\n","    # Compute Grad-CAM++ heatmap\n","    grad_cam_plus_plus = conv_output[0] * grad_cam_plus_plus[0]\n","    grad_cam_plus_plus = np.maximum(grad_cam_plus_plus, 0)\n","\n","    # Resize heatmap to the size of the input image\n","    heatmap = cv2.resize(grad_cam_plus_plus, (image.shape[2], image.shape[1]))\n","\n","    # Normalize heatmap\n","    heatmap = heatmap - np.min(heatmap)\n","    heatmap = heatmap / np.max(heatmap)\n","\n","    # Convert heatmap to RGB\n","    heatmap = np.uint8(255 * heatmap)\n","    heatmap = cv2.applyColorMap(heatmap, colormap)\n","\n","    # Combine heatmap with original image\n","    cam = cv2.addWeighted(image[0], 0.8, heatmap, 0.4, 0)\n","\n","    return cam\n","\n","# Load SegNet model\n","segnet_model = tf.keras.models.load_model('./segnet_model.h5')\n","\n","# Define image path\n","image_path = '/content/drive/MyDrive/Sample.jpeg'\n","\n","# Load and preprocess image\n","img = image.load_img(image_path, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array = imagenet_utils.preprocess_input(img_array)\n","\n","# Get predicted class index\n","predictions = segnet_model.predict(img_array)\n","predicted_class_index = np.argmax(predictions)\n","\n","# Perform Grad-CAM++ visualization\n","cam = grad_cam_plus_plus(segnet_model, img_array, 'conv2d_31', predicted_class_index)\n","\n","# Display the Grad-CAM++ visualization\n","cv2.imshow('Grad-CAM++', cam)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]}]}